---
title: Latest 15 Papers - February 14, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Large Language Models
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[Examining Multilingual Embedding Models Cross-Lingually Through LLM-Generated Adversarial Examples](http://arxiv.org/abs/2502.08638v1)** | 2025-02-12 |  |
| **[Ensemble based approach to quantifying uncertainty of LLM based classifications](http://arxiv.org/abs/2502.08631v1)** | 2025-02-12 |  |
| **[Ola: Pushing the Frontiers of Omni-Modal Language Model with Progressive Modality Alignment](http://arxiv.org/abs/2502.04328v2)** | 2025-02-12 |  |
| **[ARR: Question Answering with Large Language Models via Analyzing, Retrieving, and Reasoning](http://arxiv.org/abs/2502.04689v2)** | 2025-02-12 | <details><summary>20 pa...</summary><p>20 pages. Code: https://github.com/YuweiYin/ARR</p></details> |
| **[Evaluating the Performance of ChatGPT for Spam Email Detection](http://arxiv.org/abs/2402.15537v3)** | 2025-02-12 | <details><summary>12 pa...</summary><p>12 pages, 4 figures; Accepted by Pacific Journal of Optimization (PJO)</p></details> |
| **[ETM: Modern Insights into Perspective on Text-to-SQL Evaluation in the Age of Large Language Models](http://arxiv.org/abs/2407.07313v3)** | 2025-02-12 |  |
| **[Commercial LLM Agents Are Already Vulnerable to Simple Yet Dangerous Attacks](http://arxiv.org/abs/2502.08586v1)** | 2025-02-12 |  |
| **[Topic-Aware Knowledge Graph with Large Language Models for Interoperability in Recommender Systems](http://arxiv.org/abs/2412.20163v3)** | 2025-02-12 | <details><summary>Accep...</summary><p>Accepted by The 40th ACM/SIGAPP Symposium On Applied Computing(SAC) 2025</p></details> |
| **[URSA: Understanding and Verifying Chain-of-thought Reasoning in Multimodal Mathematics](http://arxiv.org/abs/2501.04686v3)** | 2025-02-12 | <details><summary>Fix t...</summary><p>Fix typos and add results. 27 pages, 11 tables, 17 figures. Models, training data and code have been open-sourced. Project url: https://ursa-math.github.io</p></details> |
| **[TimeSuite: Improving MLLMs for Long Video Understanding via Grounded Tuning](http://arxiv.org/abs/2410.19702v2)** | 2025-02-12 | Accepted by ICLR2025 |
| **[QA-Expand: Multi-Question Answer Generation for Enhanced Query Expansion in Information Retrieval](http://arxiv.org/abs/2502.08557v1)** | 2025-02-12 | 8 pages |
| **[Fostering Appropriate Reliance on Large Language Models: The Role of Explanations, Sources, and Inconsistencies](http://arxiv.org/abs/2502.08554v1)** | 2025-02-12 | <details><summary>CHI 2...</summary><p>CHI 2025. This version includes the appendix</p></details> |
| **[LLMs can implicitly learn from mistakes in-context](http://arxiv.org/abs/2502.08550v1)** | 2025-02-12 |  |
| **[LLM Pretraining with Continuous Concepts](http://arxiv.org/abs/2502.08524v1)** | 2025-02-12 |  |
| **[The Paradox of Stochasticity: Limited Creativity and Computational Decoupling in Temperature-Varied LLM Outputs of Structured Fictional Data](http://arxiv.org/abs/2502.08515v1)** | 2025-02-12 | 8 pages, 6 figures |

## Reinforcement Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[A Real-to-Sim-to-Real Approach to Robotic Manipulation with VLM-Generated Iterative Keypoint Rewards](http://arxiv.org/abs/2502.08643v1)** | 2025-02-12 | <details><summary>ICRA ...</summary><p>ICRA 2025, Project Page: https://iker-robot.github.io/</p></details> |
| **[Necessary and Sufficient Oracles: Toward a Computational Taxonomy For Reinforcement Learning](http://arxiv.org/abs/2502.08632v1)** | 2025-02-12 | 84 pages, 2 figures |
| **[Efficient IAM Greybox Penetration Testing](http://arxiv.org/abs/2304.14540v7)** | 2025-02-12 |  |
| **[Deep Reinforcement Learning for Bipedal Locomotion: A Brief Survey](http://arxiv.org/abs/2404.17070v3)** | 2025-02-12 | 17 pages, 8 figures |
| **[Learning Humanoid Standing-up Control across Diverse Postures](http://arxiv.org/abs/2502.08378v1)** | 2025-02-12 | <details><summary>Human...</summary><p>Humanoid Standing-up Control, 12 pages</p></details> |
| **[Towards Principled Multi-Agent Task Agnostic Exploration](http://arxiv.org/abs/2502.08365v1)** | 2025-02-12 |  |
| **[Hierarchical Learning-based Graph Partition for Large-scale Vehicle Routing Problems](http://arxiv.org/abs/2502.08340v1)** | 2025-02-12 | <details><summary>Accep...</summary><p>Accepted as a Full Paper at AAMAS 2025 (24th International Conference on Autonomous Agents and Multiagent Systems)</p></details> |
| **[Hierarchical Multi-Agent Framework for Carbon-Efficient Liquid-Cooled Data Center Clusters](http://arxiv.org/abs/2502.08337v1)** | 2025-02-12 |  |
| **[Salience-Invariant Consistent Policy Learning for Generalization in Visual Reinforcement Learning](http://arxiv.org/abs/2502.08336v1)** | 2025-02-12 |  |
| **[Noise-conditioned Energy-based Annealed Rewards (NEAR): A Generative Framework for Imitation Learning from Observation](http://arxiv.org/abs/2501.14856v2)** | 2025-02-12 | <details><summary>Accep...</summary><p>Accepted as a conference paper at the International Conference on Learning Representations (ICLR) 2025. Revised to include review feedback</p></details> |
| **[The Danger of Overthinking: Examining the Reasoning-Action Dilemma in Agentic Tasks](http://arxiv.org/abs/2502.08235v1)** | 2025-02-12 |  |
| **[Geometry-aware RL for Manipulation of Varying Shapes and Deformable Objects](http://arxiv.org/abs/2502.07005v2)** | 2025-02-12 | <details><summary>Accep...</summary><p>Accept at ICLR 2025 (Oral)</p></details> |
| **[Sample-Efficient Reinforcement Learning from Human Feedback via Information-Directed Sampling](http://arxiv.org/abs/2502.05434v2)** | 2025-02-12 |  |
| **[Tackling Data Corruption in Offline Reinforcement Learning via Sequence Modeling](http://arxiv.org/abs/2407.04285v2)** | 2025-02-12 | Accepted by ICLR2025 |
| **[Soft Diffusion Actor-Critic: Efficient Online Reinforcement Learning for Diffusion Policy](http://arxiv.org/abs/2502.00361v2)** | 2025-02-12 | 19 pages, 4 figures |

