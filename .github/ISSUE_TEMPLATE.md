---
title: Latest 15 Papers - February 04, 2025
labels: documentation
---
**Please check the [Github](https://github.com/zezhishao/MTS_Daily_ArXiv) page for a better reading experience and more papers.**

## Large Language Models
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LLMs Are In-Context Bandit Reinforcement Learners](http://arxiv.org/abs/2410.05362v2)** | 2025-01-31 |  |
| **[Vintix: Action Model via In-Context Reinforcement Learning](http://arxiv.org/abs/2501.19400v1)** | 2025-01-31 | Preprint. In review |
| **[Do LLMs Strategically Reveal, Conceal, and Infer Information? A Theoretical and Empirical Analysis in The Chameleon Game](http://arxiv.org/abs/2501.19398v1)** | 2025-01-31 |  |
| **[Cache Me If You Must: Adaptive Key-Value Quantization for Large Language Models](http://arxiv.org/abs/2501.19392v1)** | 2025-01-31 | <details><summary>Prepr...</summary><p>Preprint, under review</p></details> |
| **[Federated Sketching LoRA: On-Device Collaborative Fine-Tuning of Large Language Models](http://arxiv.org/abs/2501.19389v1)** | 2025-01-31 | 23 pages |
| **[SELMA: A Speech-Enabled Language Model for Virtual Assistant Interactions](http://arxiv.org/abs/2501.19377v1)** | 2025-01-31 | <details><summary>Accep...</summary><p>Accepted at ICASSP 2025</p></details> |
| **[GPT-4o as the Gold Standard: A Scalable and General Purpose Approach to Filter Language Model Pretraining Data](http://arxiv.org/abs/2410.02755v3)** | 2025-01-31 |  |
| **[We're Different, We're the Same: Creative Homogeneity Across LLMs](http://arxiv.org/abs/2501.19361v1)** | 2025-01-31 |  |
| **[The Energy Loss Phenomenon in RLHF: A New Perspective on Mitigating Reward Hacking](http://arxiv.org/abs/2501.19358v1)** | 2025-01-31 | 28 pages, 21 figures |
| **[Towards Adaptive Self-Improvement for Smarter Energy Systems](http://arxiv.org/abs/2501.19340v1)** | 2025-01-31 |  |
| **[FlexiGPT: Pruning and Extending Large Language Models with Low-Rank Weight Sharing](http://arxiv.org/abs/2501.14713v2)** | 2025-01-31 | <details><summary>Accep...</summary><p>Accepted to NAACL 2025 - Main Conference</p></details> |
| **[Homogeneity Bias as Differential Sampling Uncertainty in Language Models](http://arxiv.org/abs/2501.19337v1)** | 2025-01-31 |  |
| **[From Natural Language to Extensive-Form Game Representations](http://arxiv.org/abs/2501.17282v3)** | 2025-01-31 | <details><summary>This ...</summary><p>This work has been accepted as a full paper for AAMAS 2025. This is a full version of the AAMAS 2025 proceedings</p></details> |
| **[Reward-Guided Speculative Decoding for Efficient LLM Reasoning](http://arxiv.org/abs/2501.19324v1)** | 2025-01-31 | 17 pages |
| **[MINDSTORES: Memory-Informed Neural Decision Synthesis for Task-Oriented Reinforcement in Embodied Systems](http://arxiv.org/abs/2501.19318v1)** | 2025-01-31 |  |

## Reinforcement Learning
| **Title** | **Date** | **Comment** |
| --- | --- | --- |
| **[LLMs Are In-Context Bandit Reinforcement Learners](http://arxiv.org/abs/2410.05362v2)** | 2025-01-31 |  |
| **[Diverse Preference Optimization](http://arxiv.org/abs/2501.18101v2)** | 2025-01-31 |  |
| **[Vintix: Action Model via In-Context Reinforcement Learning](http://arxiv.org/abs/2501.19400v1)** | 2025-01-31 | Preprint. In review |
| **[The Energy Loss Phenomenon in RLHF: A New Perspective on Mitigating Reward Hacking](http://arxiv.org/abs/2501.19358v1)** | 2025-01-31 | 28 pages, 21 figures |
| **[Drama: Mamba-Enabled Model-Based Reinforcement Learning Is Sample and Parameter Efficient](http://arxiv.org/abs/2410.08893v2)** | 2025-01-31 |  |
| **[Jackpot! Alignment as a Maximal Lottery](http://arxiv.org/abs/2501.19266v1)** | 2025-01-31 |  |
| **[Objective Metrics for Human-Subjects Evaluation in Explainable Reinforcement Learning](http://arxiv.org/abs/2501.19256v1)** | 2025-01-31 |  |
| **[Linear $Q$-Learning Does Not Diverge: Convergence Rates to a Bounded Set](http://arxiv.org/abs/2501.19254v1)** | 2025-01-31 |  |
| **[TOP-ERL: Transformer-based Off-Policy Episodic Reinforcement Learning](http://arxiv.org/abs/2410.09536v2)** | 2025-01-31 | <details><summary>Codeb...</summary><p>Codebase: https://github.com/BruceGeLi/TOP_ERL_ICLR25. arXiv admin note: text overlap with arXiv:2401.11437</p></details> |
| **[SHARPIE: A Modular Framework for Reinforcement Learning and Human-AI Interaction Experiments](http://arxiv.org/abs/2501.19245v1)** | 2025-01-31 |  |
| **[Policy Gradient Methods for Risk-Sensitive Distributional Reinforcement Learning with Provable Convergence](http://arxiv.org/abs/2405.14749v2)** | 2025-01-31 |  |
| **[An Empirical Game-Theoretic Analysis of Autonomous Cyber-Defence Agents](http://arxiv.org/abs/2501.19206v1)** | 2025-01-31 | <details><summary>21 pa...</summary><p>21 pages, 17 figures, 10 tables</p></details> |
| **[Stable Offline Value Function Learning with Bisimulation-based Representations](http://arxiv.org/abs/2410.01643v3)** | 2025-01-31 | Under review |
| **[Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection](http://arxiv.org/abs/2409.15844v2)** | 2025-01-31 |  |
| **[APEX: Automated Parameter Exploration for Low-Power Wireless Protocols](http://arxiv.org/abs/2501.19194v1)** | 2025-01-31 | 28 pages, 13 figures |

